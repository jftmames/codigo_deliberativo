import os
import json
import streamlit as st
import openai
from modules.reasoning_tracker import ReasoningTracker
from modules.html_exporter import generate_html_report

# ---- 0. ConfiguraciÃ³n de pÃ¡gina ----
st.set_page_config(
    page_title="CÃ³digo Deliberativo Educativo",
    page_icon="ğŸ§ ",
    layout="wide"
)

# ---- 1. Barra lateral â€“ Ajustes ----
st.sidebar.header("ğŸ”§ Ajustes")
mode = st.sidebar.selectbox(
    "Perfil del usuario",
    ["Asistido (bÃ¡sico)", "Guiado (intermedio)", "Exploratorio (avanzado)"]
)
st.sidebar.markdown("---")
st.sidebar.info("Grupo de InvestigaciÃ³n en IA.")

# ---- Opcional: BotÃ³n para reset total manual ----
if st.sidebar.button("ğŸ”„ Nuevo razonamiento / Reset"):
    for k in list(st.session_state.keys()):
        del st.session_state[k]
    st.experimental_rerun()

# ---- 2. TÃ­tulo principal ----
st.title("ğŸ§  CÃ³digo Deliberativo para Pensamiento CrÃ­tico")
st.markdown(
    """
    Esta aplicaciÃ³n te guÃ­a paso a paso para **estructurar**, **explorar** y **evaluar**
    procesos de indagaciÃ³n crÃ­ticos, usando un modelo de IA deliberativa.
    """
)

# ---- 3. Entrada de la pregunta ----
st.header("1. Define tu pregunta raÃ­z")
example_questions = [
    "Â¿Es Ã©tico el uso de IA en diagnÃ³sticos mÃ©dicos?",
    "Â¿DeberÃ­an las redes sociales regular cierto tipo de contenido?",
    "Â¿CÃ³mo impacta la automatizaciÃ³n en el mercado laboral juvenil?",
    "Â¿Es sostenible el modelo econÃ³mico actual?",
    "Â¿Debe implementarse la renta bÃ¡sica universal?"
]
selected_example = st.selectbox("Ejemplos de preguntas", ["â€” Ninguno â€”"] + example_questions)
if selected_example != "â€” Ninguno â€”":
    root_question = selected_example
    st.markdown(f"**Pregunta seleccionada:** {root_question}")
else:
    root_question = st.text_input(
        "Escribe tu pregunta aquÃ­",
        placeholder="Ej. Â¿Es Ã©tico el uso de IA en diagnÃ³sticos mÃ©dicos?",
    )
if not root_question:
    st.warning("ğŸ›ˆ Necesitamos una pregunta raÃ­z para continuar.")
    st.stop()

# ---- RESET AUTOMÃTICO AL CAMBIAR DE PREGUNTA ----
if (
    "last_root_question" not in st.session_state
    or st.session_state["last_root_question"] != root_question
):
    # Resetea el tracker y los campos relacionados
    st.session_state["tracker"] = ReasoningTracker(root_question)
    st.session_state["last_root_question"] = root_question
    st.session_state.pop("node_selected", None)
    st.session_state.pop("respuestas_multiperspectiva", None)

# ---- 4. PreparaciÃ³n OpenAI ----
openai.api_key = os.getenv("OPENAI_API_KEY")
def chat(messages, max_tokens=500):
    return openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        temperature=0.7,
        max_tokens=max_tokens,
    )

# ---- 5. Definir marcos multiperspectiva ----
PERSPECTIVES = {
    "Ã‰tica": "Desde una perspectiva Ã©tica (deontologÃ­a, utilitarismo, Ã©tica del cuidado)...",
    "HistÃ³rico-Social": "Desde una perspectiva histÃ³rica o sociopolÃ­tica relevante...",
    "EpistemolÃ³gica": "Desde una perspectiva crÃ­tica epistemolÃ³gica o filosÃ³fica..."
}

# ---- 6. GeneraciÃ³n de Ã¡rboles multiperspectiva ----
def generate_trees(root_question, chat_fn):
    trees = {}
    for marco, intro in PERSPECTIVES.items():
        prompt = (
            f"{intro}\n"
            f"Pregunta raÃ­z: â€œ{root_question}â€\n"
            "1. Identifica 3â€“5 subpreguntas necesarias para el anÃ¡lisis crÃ­tico.\n"
            "2. OrganÃ­zalas en estructura jerÃ¡rquica.\n"
            "Devuelve solo JSON: {{ 'node': '...', 'children': [ ... ] }}"
        )
        resp = chat_fn([{"role": "system", "content": prompt}], max_tokens=600)
        try:
            trees[marco] = json.loads(resp.choices[0].message.content)
        except Exception:
            trees[marco] = {"node": "Error al generar", "children": []}
    return trees

with st.spinner("Generando Ã¡rboles multiperspectivaâ€¦"):
    trees = generate_trees(root_question, chat)

# ---- 7. VisualizaciÃ³n y navegaciÃ³n ----
st.header("2. Explora los Ã¡rboles desde diferentes perspectivas")
marco = st.selectbox("Elige perspectiva de anÃ¡lisis", list(trees.keys()))
st.subheader(f"Ãrbol de subpreguntas ({marco})")

def build_dot(node):
    node_name = node.get("node", "<sin etiqueta>")
    node_state = st.session_state["tracker"].log.get("node_states", {}).get(node_name, {}).get("state", "Abierta")
    color_map = {
        "Abierta": "limegreen",
        "Resuelta": "deepskyblue",
        "En disputa": "orange",
        "Suspendida": "gray"
    }
    emoji_map = {
        "Abierta": "ğŸŸ¢",
        "Resuelta": "ğŸ”µ",
        "En disputa": "ğŸŸ ",
        "Suspendida": "âšª"
    }
    color = color_map.get(node_state, "black")
    emoji = emoji_map.get(node_state, "ğŸŸ¢")
    label = f"{emoji} {node_name}"

    dot = f'"{label}" [style=filled, fillcolor={color}, shape=box, fontname="Arial", fontsize=14];\n'
    for child in node.get("children", []):
        c_label = child.get("node", "<sin etiqueta>")
        child_state = st.session_state["tracker"].log.get("node_states", {}).get(c_label, {}).get("state", "Abierta")
        c_emoji = emoji_map.get(child_state, "ğŸŸ¢")
        c_label_full = f"{c_emoji} {c_label}"
        dot += f'"{label}" -> "{c_label_full}";\n'
        dot += build_dot(child)
    return dot

root = trees[marco]
dot = f'digraph G {{\nrankdir=TB;\nnode [style=filled, fontname="Arial"];\n{build_dot(root)}}}'
st.graphviz_chart(dot, use_container_width=True)

with st.expander("Ver leyenda de colores del grafo"):
    st.markdown(
        """
        **ğŸŸ¢ Abierta**: Subpregunta aÃºn en anÃ¡lisis  
        **ğŸ”µ Resuelta**: Subpregunta cerrada/resuelta  
        **ğŸŸ  En disputa**: Subpregunta en debate o sin consenso  
        **âšª Suspendida**: Subpregunta postergada/no relevante  
        """
    )

with st.expander("Mostrar subpreguntas en formato de lista"):
    def render_list(node, indent=0):
        node_name = node.get('node', '<sin tÃ­tulo>')
        node_state = st.session_state["tracker"].log.get("node_states", {}).get(node_name, {}).get("state", "Abierta")
        emoji = {"Abierta":"ğŸŸ¢", "Resuelta":"ğŸ”µ", "En disputa":"ğŸŸ ", "Suspendida":"âšª"}.get(node_state,"ğŸŸ¢")
        st.markdown(" " * indent * 2 + f"- {emoji} **{node_name}**")
        for c in node.get("children", []):
            render_list(c, indent + 1)
    render_list(root)

# ---- 8. SelecciÃ³n de nodo, estado y justificaciÃ³n ----
node_selected = st.text_input("Â¿Sobre quÃ© subpregunta quieres profundizar?")
if st.button("Seleccionar subpregunta"):
    st.session_state["tracker"].log_event("seleccion", node_selected, marco=marco)
    st.session_state["node_selected"] = node_selected

if "node_selected" in st.session_state:
    st.subheader("Estado epistÃ©mico de la subpregunta")
    estados = {
        "Abierta": "ğŸŸ¢ Abierta",
        "Resuelta": "ğŸ”µ Resuelta",
        "En disputa": "ğŸŸ  En disputa",
        "Suspendida": "âšª Suspendida"
    }
    estado_actual = st.session_state["tracker"].log.get("node_states", {}).get(
        st.session_state["node_selected"], {}
    ).get("state", "Abierta")
    nuevo_estado = st.radio(
        "Selecciona el estado actual de esta subpregunta:",
        list(estados.keys()),
        index=list(estados.keys()).index(estado_actual) if estado_actual in estados else 0,
        format_func=lambda x: estados[x]
    )
    if st.button("Actualizar estado epistÃ©mico"):
        st.session_state["tracker"].set_node_state(st.session_state["node_selected"], nuevo_estado)
        st.success(f"Estado actualizado a: {estados[nuevo_estado]}")

    st.subheader("Justifica tu selecciÃ³n antes de continuar")
    justificacion = st.text_area("Explica por quÃ© esta subpregunta es clave para la indagaciÃ³n:")
    if st.button("Guardar justificaciÃ³n y avanzar"):
        st.session_state["tracker"].log_event(
            "justificacion",
            justificacion,
            marco=marco,
            parent_node=st.session_state["node_selected"]
        )
        st.success("JustificaciÃ³n registrada. Puedes avanzar.")

    st.subheader("Feedback plural (pares/docente) sobre esta subpregunta")
    comment_text = st.text_area("Deja aquÃ­ tu comentario sobre la subpregunta, respuesta o reflexiÃ³n del usuario:", key="comment_text")
    comment_author = st.text_input("Tu nombre o alias:", key="comment_author")
    tipo = st.radio("Tipo de feedback:", ("Humano (pares/docente)", "IA"), key="tipo_feedback")
    if st.button("AÃ±adir comentario"):
        st.session_state["tracker"].add_feedback(
            st.session_state["node_selected"],
            comment_text,
            author=comment_author if comment_author else "AnÃ³nimo",
            tipo=tipo
        )
        st.success("Â¡Comentario aÃ±adido!")

    feedbacks = st.session_state["tracker"].log.get("feedback", {}).get(st.session_state["node_selected"], [])
    if feedbacks:
        st.markdown("#### Comentarios recibidos:")
        for fb in feedbacks:
            st.markdown(f"- _{fb['author']} ({fb['tipo']}):_ {fb['comment']}")
    else:
        st.info("AÃºn no hay comentarios en esta subpregunta.")

# ---- 9. Generar y comparar respuestas multiperspectiva ----
def generar_respuestas_multiperspectiva(nodo, marco, chat_fn):
    prompt = (
        f"Analiza la siguiente cuestiÃ³n desde tres perspectivas.\n"
        f"Subpregunta: â€œ{nodo}â€\n"
        f"Marco seleccionado: {marco}\n"
        "Proporciona tres respuestas bien argumentadas y diferenciadas:\n"
        "1. Perspectiva Ã©tica (deontologÃ­a, utilitarismo, Ã©tica del cuidado).\n"
        "2. Perspectiva histÃ³rico-sociopolÃ­tica relevante.\n"
        "3. Perspectiva crÃ­tica epistemolÃ³gica o filosÃ³fica.\n"
        "Responde solo en JSON:\n"
        '[{"label": "Ã‰tica", "text": "..."}, {"label": "HistÃ³rico-Social", "text": "..."}, {"label": "EpistemolÃ³gica", "text": "..."}]'
    )
    r = chat_fn([{"role": "system", "content": prompt}], max_tokens=700)
    try:
        data = json.loads(r.choices[0].message.content)
    except Exception:
        data = []
    return data

if "node_selected" in st.session_state:
    st.subheader("Genera y compara respuestas multiperspectiva")
    if st.button("Obtener respuestas multiperspectiva"):
        respuestas = generar_respuestas_multiperspectiva(
            st.session_state["node_selected"], marco, chat
        )
        st.session_state["respuestas_multiperspectiva"] = respuestas
        st.session_state["tracker"].log_event(
            "respuestas_multiperspectiva",
            respuestas,
            marco=marco,
            parent_node=st.session_state["node_selected"]
        )

if "respuestas_multiperspectiva" in st.session_state:
    st.markdown("### Respuestas contrastadas para la subpregunta seleccionada:")
    for item in st.session_state["respuestas_multiperspectiva"]:
        st.markdown(f"**{item['label']}**: {item['text']}")
    st.info("Reflexiona y compara las respuestas antes de continuar.")

    seleccion_usuario = st.radio(
        "Â¿CuÃ¡l perspectiva te parece mÃ¡s fundamentada/interesante para este caso?",
        [r["label"] for r in st.session_state["respuestas_multiperspectiva"]],
        index=0,
        key="seleccion_perspectiva"
    )
    justificacion_usuario = st.text_area(
        "Â¿Por quÃ© escoges esa perspectiva como la mÃ¡s relevante aquÃ­? Â¿CambiarÃ­a algo si eligieras otra?",
        key="justificacion_perspectiva"
    )
    if st.button("Registrar elecciÃ³n y reflexiÃ³n"):
        st.session_state["tracker"].log_event(
            "eleccion_perspectiva",
            {
                "perspectiva": seleccion_usuario,
                "justificacion": justificacion_usuario
            },
            marco=marco,
            parent_node=st.session_state["node_selected"]
        )
        st.success("ElecciÃ³n y reflexiÃ³n registradas.")

# ---- 10. ExportaciÃ³n y visualizaciÃ³n de Reasoning Tracker ----
st.header("3. Exporta y revisa tu proceso deliberativo")
razonamiento = st.session_state["tracker"].export()
st.download_button("Descargar razonamiento (JSON)", razonamiento, file_name="razonamiento.json")

import io
if st.button("Descargar informe deliberativo en HTML"):
    html_content = generate_html_report(st.session_state["tracker"].log)
    st.download_button("Descargar informe (HTML)", data=html_content, file_name="informe_deliberativo.html", mime="text/html")

if st.checkbox("Ver historial de razonamiento"):
    st.json(st.session_state["tracker"].log)

st.info("VersiÃ³n en construcciÃ³n: ahora con estados epistÃ©micos, feedback plural, colores y emojis en el Ã¡rbol deliberativo.")

