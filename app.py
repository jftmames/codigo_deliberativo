import os
import json
import streamlit as st
import openai
from modules.reasoning_tracker import ReasoningTracker

# ---- 0. Configuraci√≥n de p√°gina ----
st.set_page_config(
    page_title="C√≥digo Deliberativo Educativo",
    page_icon="üß†",
    layout="wide"
)

# ---- 1. Barra lateral ‚Äì Ajustes ----
st.sidebar.header("üîß Ajustes")
mode = st.sidebar.selectbox(
    "Perfil del usuario",
    ["Asistido (b√°sico)", "Guiado (intermedio)", "Exploratorio (avanzado)"]
)
st.sidebar.markdown("---")
st.sidebar.info("Aseg√∫rate de haber configurado tu variable de entorno `OPENAI_API_KEY`.")

# ---- 2. T√≠tulo principal ----
st.title("üß† C√≥digo Deliberativo para Pensamiento Cr√≠tico")
st.markdown(
    """
    Esta aplicaci√≥n te gu√≠a paso a paso para **estructurar**, **explorar** y **evaluar**
    procesos de indagaci√≥n cr√≠ticos, usando un modelo de IA deliberativa.
    """
)

# ---- 3. Entrada de la pregunta ----
st.header("1. Define tu pregunta ra√≠z")
example_questions = [
    "¬øEs √©tico el uso de IA en diagn√≥sticos m√©dicos?",
    "¬øDeber√≠an las redes sociales regular cierto tipo de contenido?",
    "¬øC√≥mo impacta la automatizaci√≥n en el mercado laboral juvenil?",
    "¬øEs sostenible el modelo econ√≥mico actual?",
    "¬øDebe implementarse la renta b√°sica universal?"
]
selected_example = st.selectbox("Ejemplos de preguntas", ["‚Äî Ninguno ‚Äî"] + example_questions)
if selected_example != "‚Äî Ninguno ‚Äî":
    root_question = selected_example
    st.markdown(f"**Pregunta seleccionada:** {root_question}")
else:
    root_question = st.text_input(
        "Escribe tu pregunta aqu√≠",
        placeholder="Ej. ¬øEs √©tico el uso de IA en diagn√≥sticos m√©dicos?",
    )
if not root_question:
    st.warning("üõà Necesitamos una pregunta ra√≠z para continuar.")
    st.stop()

# ---- 4. Inicializa Reasoning Tracker (debe ir despu√©s de definir root_question) ----
if "tracker" not in st.session_state:
    st.session_state["tracker"] = ReasoningTracker(root_question)

# ---- 5. Preparaci√≥n OpenAI ----
openai.api_key = os.getenv("OPENAI_API_KEY")
def chat(messages, max_tokens=500):
    return openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        temperature=0.7,
        max_tokens=max_tokens,
    )

# ---- 6. Definir marcos multiperspectiva ----
PERSPECTIVES = {
    "√âtica": "Desde una perspectiva √©tica (deontolog√≠a, utilitarismo, √©tica del cuidado)...",
    "Hist√≥rico-Social": "Desde una perspectiva hist√≥rica o sociopol√≠tica relevante...",
    "Epistemol√≥gica": "Desde una perspectiva cr√≠tica epistemol√≥gica o filos√≥fica..."
}

# ---- 7. Generaci√≥n de √°rboles multiperspectiva ----
def generate_trees(root_question, chat_fn):
    trees = {}
    for marco, intro in PERSPECTIVES.items():
        prompt = (
            f"{intro}\n"
            f"Pregunta ra√≠z: ‚Äú{root_question}‚Äù\n"
            "1. Identifica 3‚Äì5 subpreguntas necesarias para el an√°lisis cr√≠tico.\n"
            "2. Organ√≠zalas en estructura jer√°rquica.\n"
            "Devuelve solo JSON: { 'node': '...', 'children': [ ... ] }"
        )
        resp = chat_fn([{"role": "system", "content": prompt}], max_tokens=600)
        try:
            trees[marco] = json.loads(resp.choices[0].message.content)
        except Exception:
            trees[marco] = {"node": "Error al generar", "children": []}
    return trees

with st.spinner("Generando √°rboles multiperspectiva‚Ä¶"):
    trees = generate_trees(root_question, chat)

# ---- 8. Visualizaci√≥n y navegaci√≥n ----
st.header("2. Explora los √°rboles desde diferentes perspectivas")
marco = st.selectbox("Elige perspectiva de an√°lisis", list(trees.keys()))
st.subheader(f"√Årbol de subpreguntas ({marco})")

def build_dot(node):
    edges = ""
    label = node.get("node", "<sin etiqueta>")
    for child in node.get("children", []):
        c_label = child.get("node", "<sin etiqueta>")
        edges += f"\"{label}\" -> \"{c_label}\";\n"
        edges += build_dot(child)
    return edges

root = trees[marco]
dot = f"digraph G {{\n{build_dot(root)}}}"
st.graphviz_chart(dot, use_container_width=True)

# Listado anidado
with st.expander("Mostrar subpreguntas en formato de lista"):
    def render_list(node, indent=0):
        st.markdown(" " * indent * 2 + f"- **{node.get('node', '<sin t√≠tulo>')}**")
        for c in node.get("children", []):
            render_list(c, indent + 1)
    render_list(root)

# ---- 9. Selecci√≥n de nodo y justificaci√≥n ----
node_selected = st.text_input("¬øSobre qu√© subpregunta quieres profundizar?")
if st.button("Seleccionar subpregunta"):
    st.session_state["tracker"].log_event("seleccion", node_selected, marco=marco)
    st.session_state["node_selected"] = node_selected

if "node_selected" in st.session_state:
    st.subheader("Justifica tu selecci√≥n antes de continuar")
    justificacion = st.text_area("Explica por qu√© esta subpregunta es clave para la indagaci√≥n:")
    if st.button("Guardar justificaci√≥n y avanzar"):
        st.session_state["tracker"].log_event(
            "justificacion",
            justificacion,
            marco=marco,
            parent_node=st.session_state["node_selected"]
        )
        st.success("Justificaci√≥n registrada. Puedes avanzar.")

# ---- 10. Generar y comparar respuestas multiperspectiva ----
def generar_respuestas_multiperspectiva(nodo, marco, chat_fn):
    prompt = (
        f"Analiza la siguiente cuesti√≥n desde tres perspectivas.\n"
        f"Subpregunta: ‚Äú{nodo}‚Äù\n"
        f"Marco seleccionado: {marco}\n"
        "Proporciona tres respuestas bien argumentadas y diferenciadas:\n"
        "1. Perspectiva √©tica (deontolog√≠a, utilitarismo, √©tica del cuidado).\n"
        "2. Perspectiva hist√≥rico-sociopol√≠tica relevante.\n"
        "3. Perspectiva cr√≠tica epistemol√≥gica o filos√≥fica.\n"
        "Responde solo en JSON:\n"
        '[{"label": "√âtica", "text": "..."}, {"label": "Hist√≥rico-Social", "text": "..."}, {"label": "Epistemol√≥gica", "text": "..."}]'
    )
    r = chat_fn([{"role": "system", "content": prompt}], max_tokens=700)
    try:
        data = json.loads(r.choices[0].message.content)
    except Exception:
        data = []
    return data

if "node_selected" in st.session_state:
    st.subheader("Genera y compara respuestas multiperspectiva")
    if st.button("Obtener respuestas multiperspectiva"):
        respuestas = generar_respuestas_multiperspectiva(
            st.session_state["node_selected"], marco, chat
        )
        st.session_state["respuestas_multiperspectiva"] = respuestas
        # Registrar en el tracker
        st.session_state["tracker"].log_event(
            "respuestas_multiperspectiva",
            respuestas,
            marco=marco,
            parent_node=st.session_state["node_selected"]
        )

if "respuestas_multiperspectiva" in st.session_state:
    st.markdown("### Respuestas contrastadas para la subpregunta seleccionada:")
    for item in st.session_state["respuestas_multiperspectiva"]:
        st.markdown(f"**{item['label']}**: {item['text']}")
    st.info("Reflexiona y compara las respuestas antes de continuar.")

    seleccion_usuario = st.radio(
        "¬øCu√°l perspectiva te parece m√°s fundamentada/interesante para este caso?",
        [r["label"] for r in st.session_state["respuestas_multiperspectiva"]],
        index=0,
        key="seleccion_perspectiva"
    )
    justificacion_usuario = st.text_area(
        "¬øPor qu√© escoges esa perspectiva como la m√°s relevante aqu√≠? ¬øCambiar√≠a algo si eligieras otra?",
        key="justificacion_perspectiva"
    )
    if st.button("Registrar elecci√≥n y reflexi√≥n"):
        st.session_state["tracker"].log_event(
            "eleccion_perspectiva",
            {
                "perspectiva": seleccion_usuario,
                "justificacion": justificacion_usuario
            },
            marco=marco,
            parent_node=st.session_state["node_selected"]
        )
        st.success("Elecci√≥n y reflexi√≥n registradas.")

# ---- 11. Exportaci√≥n y visualizaci√≥n de Reasoning Tracker ----
st.header("3. Exporta y revisa tu proceso deliberativo")
if st.button("Exportar proceso deliberativo"):
    razonamiento = st.session_state["tracker"].export()
    st.download_button("Descargar razonamiento (JSON)", razonamiento, file_name="razonamiento.json")

if st.checkbox("Ver historial de razonamiento"):
    st.json(st.session_state["tracker"].log)

st.info("Esta versi√≥n integra deliberaci√≥n plural y trazabilidad. Siguiente paso sugerido: feedback plural, EEE, panel colaborativo o exportaci√≥n HTML enriquecida.")
